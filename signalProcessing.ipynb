{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy, IPython.display as ipd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "import pywt\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess audio \n",
    "**Label audio segments: Hammering Sound Detection** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Recording-total-hip-summarized'\n",
    "\n",
    "y, sr = librosa.load(f'voice/{filename}.wav')\n",
    "\n",
    "ipd.Audio(y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_duration = 60\n",
    "samples_per_segment = int(segment_duration * sr)\n",
    "\n",
    "# Split the audio into segments\n",
    "audio_segments = []\n",
    "for i in range(0, len(y), samples_per_segment):\n",
    "    l = len\n",
    "    segment = y[i:i + samples_per_segment]\n",
    "    segment = np.reshape(segment, (1,segment.size))\n",
    "    audio_segments.append(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio_segments[300], rate = sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_segments = [2,3,5,9,10,20,22,23,32,34]\n",
    "temp = np.concatenate([audio_segments[i] for i in Selected_segments],axis= 1)\n",
    "sf.write('voice/Recording-total-hip-summarized.wav', temp[0], sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (14, 5)\n",
    "librosa.display.waveshow(y, sr=sr)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Hammering Sound Detection')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_duration = 2\n",
    "# Calculate the number of samples per segment based on the duration\n",
    "samples_per_segment = int(segment_duration * sr)\n",
    "\n",
    "# Split the audio into segments\n",
    "audio_segments = []\n",
    "for i in range(0, len(y), samples_per_segment):\n",
    "    l = len\n",
    "    segment = y[i:i + samples_per_segment]\n",
    "    segment = np.reshape(segment, (1,segment.size))\n",
    "    audio_segments.append(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio_segments[300], rate = sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "B = [0,0,0,0,0,1,1,1,1,0,0,0,1,1,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0]\n",
    "C = [0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,0,0,0,1,0,0,0,0,0,0,0,0]\n",
    "D = [0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "E = [0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "F = [1,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,1,1,1,1,1]\n",
    "G = [0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0]\n",
    "H = [0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0]\n",
    "I = [1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "J = [1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,0,1,1,1,1,0,0,0,1,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = np.array(A + B + C + D + E+ F + G +H +I + J)\n",
    "file_name = 'Recording-total-hip'\n",
    "with open(f'Labels/{file_name}-summarized.npy', 'wb') as f:\n",
    "    np.save(f, Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(x)\n",
    "    return scaler.transform(x)\n",
    "\n",
    "# Function to extract signal-based characteristics\n",
    "def extract_characteristics(segment):\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=segment, sr=sr)[0])\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=segment, sr=sr)[0])\n",
    "    zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(segment)[0])\n",
    "    rms_energy = np.mean(librosa.feature.rms(y=segment)[0])\n",
    "    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=segment, sr=sr)[0])\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=segment, sr=sr))\n",
    "\n",
    "    return spectral_centroid, spectral_rolloff, zero_crossing_rate, rms_energy, spectral_contrast, chroma\n",
    "\n",
    "def extract_transforms(segment):\n",
    "    # Discrete Fourier Transform (DFT)\n",
    "    dft = np.abs(np.fft.fft(segment))\n",
    "    return dft\n",
    "\n",
    "segment_duration = 2\n",
    "# Calculate the number of samples per segment based on the duration\n",
    "samples_per_segment = int(segment_duration * sr)\n",
    "\n",
    "# Split the audio into segments\n",
    "audio_segments = []\n",
    "for i in range(0, len(y), samples_per_segment):\n",
    "    l = len\n",
    "    segment = y[i:i + samples_per_segment]\n",
    "    segment = np.reshape(segment, (1,segment.size))\n",
    "    audio_segments.append(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Recording-total-hip-summarized'\n",
    "y, sr = librosa.load(f'voice/{filename}.wav')\n",
    "\n",
    "with open(f'Labels/{filename}.npy', 'rb') as f:\n",
    "    Label_of_sound = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hammering_features = []\n",
    "speech_features = []\n",
    "i=0\n",
    "for  i in range(len(audio_segments)):\n",
    "    segment = audio_segments[i]\n",
    "    # features = extract_characteristics(segment)\n",
    "    features = extract_transforms(segment).flatten()\n",
    "\n",
    "    if Label_of_sound[i] == 1:\n",
    "        hammering_features.append(features)\n",
    "    else:\n",
    "        speech_features.append(features)\n",
    "\n",
    "\n",
    "X = np.vstack((hammering_features, speech_features))\n",
    "y = np.hstack((np.ones(len(hammering_features)), np.zeros(len(speech_features))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models \n",
    "- Random Forest\n",
    "- XGBOOST\n",
    "- SVM\\\n",
    "Input Features: signal-based characteristics or Discrete Fourier Transform (DFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a classifier\n",
    "classifier = RandomForestClassifier(n_estimators=200, random_state=30)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate classifier\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_rf = np.round(accuracy_score(y_test, predictions),3)\n",
    "precision_rf = np.round(precision_score(y_test, predictions),3)\n",
    "recall_rf = np.round(recall_score(y_test, predictions),3)\n",
    "f1_rf = np.round(f1_score(y_test, predictions),3)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf}\")\n",
    "print(f\"Random Forest Precision: {precision_rf}\")\n",
    "print(f\"Random Forest Recall: {recall_rf}\")\n",
    "print(f\"Random Forest F1-Score: {f1_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost classifier\n",
    "xg_clf = xgb.XGBClassifier()\n",
    "xg_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xg_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy_xgb = np.round(accuracy_score(y_test, y_pred_xgb),3)\n",
    "precision_xgb = np.round(precision_score(y_test, y_pred_xgb),3)\n",
    "recall_xgb = np.round(recall_score(y_test, y_pred_xgb),3)\n",
    "f1_xgb = np.round(f1_score(y_test, y_pred_xgb),3)\n",
    "\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb}\")\n",
    "print(f\"XGBoost Precision: {precision_xgb}\")\n",
    "print(f\"XGBoost Recall: {recall_xgb}\")\n",
    "print(f\"XGBoost F1-Score: {f1_xgb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_clf = SVC(kernel='rbf') \n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "accuracy_svm = np.round(accuracy_score(y_test, y_pred_svm),3)\n",
    "precision_svm = np.round(precision_score(y_test, y_pred_svm),3)\n",
    "recall_svm = np.round(recall_score(y_test, y_pred_svm),3)\n",
    "f1_svm = np.round(f1_score(y_test, y_pred_svm),3)\n",
    "\n",
    "print(f\"SVM Accuracy: {accuracy_svm}\")\n",
    "print(f\"SVM Precision: {precision_svm}\")\n",
    "print(f\"SVM Recall: {recall_svm}\")\n",
    "print(f\"SVM F1-Score: {f1_svm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "signal = audio_segments[2]\n",
    "\n",
    "librosa.display.waveshow(signal, sr=sr, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the trained classifier to predict hammering segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
